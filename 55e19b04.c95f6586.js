(window.webpackJsonp=window.webpackJsonp||[]).push([[14],{68:function(e,t,n){"use strict";n.r(t),n.d(t,"frontMatter",(function(){return o})),n.d(t,"metadata",(function(){return c})),n.d(t,"rightToc",(function(){return s})),n.d(t,"default",(function(){return d}));var a=n(2),r=n(6),i=(n(0),n(99)),o={id:"Intro",title:"Fish Classification",sidebar_label:"Introduction"},c={unversionedId:"classification/fish/Intro",id:"classification/fish/Intro",isDocsHomePage:!1,title:"Fish Classification",description:"In this project, the aim of is develop a demo of scientific  and intelligent tools to aid the CFIA agents with their job in detecting and correctly identifying species of fish being sold.",source:"@site/docs/classification/fish/Intro.md",permalink:"/docusaurus/docs/classification/fish/Intro",editUrl:"https://github.com/facebook/docusaurus/edit/master/website/docs/classification/fish/Intro.md",sidebar_label:"Introduction",sidebar:"classification",next:{title:"Instructions",permalink:"/docusaurus/docs/classification/fish/instructions"}},s=[{value:"Introduction",id:"introduction",children:[]},{value:"Models",id:"models",children:[]},{value:"Training code",id:"training-code",children:[]},{value:"Deployment Code",id:"deployment-code",children:[]},{value:"Dateset and analysis",id:"dateset-and-analysis",children:[]}],l={rightToc:s};function d(e){var t=e.components,n=Object(r.a)(e,["components"]);return Object(i.b)("wrapper",Object(a.a)({},l,n,{components:t,mdxType:"MDXLayout"}),Object(i.b)("p",null,"In this project, the aim of is develop a demo of scientific  and intelligent tools to aid the CFIA agents with their job in detecting and correctly identifying species of fish being sold."),Object(i.b)("h3",{id:"introduction"},"Introduction"),Object(i.b)("p",null,"In this project we made use of deep learning and neural networks to identify and classify  images of interest."),Object(i.b)("h4",{id:"data"},"Data"),Object(i.b)("p",null,"For this project we scraped the web for pictures of 16 fish species. We made use of Bing  search engine APIs for downloading the images.\nAs one can expect, the images had to be pruned and a lot of the images had to be eliminated due to irrelevance or poor quality.\nThe resulting dataset contains pictures of of 16 fish species with approximately 50~60 images per class on average.\nThe currently supported species are:"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},"Haddock"),Object(i.b)("li",{parentName:"ul"},"Hake"),Object(i.b)("li",{parentName:"ul"},"Halibut"),Object(i.b)("li",{parentName:"ul"},"Mackerel"),Object(i.b)("li",{parentName:"ul"},"Monkfish"),Object(i.b)("li",{parentName:"ul"},"Ocean Perch"),Object(i.b)("li",{parentName:"ul"},"Salmon"),Object(i.b)("li",{parentName:"ul"},"Sea Bass"),Object(i.b)("li",{parentName:"ul"},"Snapper"),Object(i.b)("li",{parentName:"ul"},"Swordfish"),Object(i.b)("li",{parentName:"ul"},"Tilapia"),Object(i.b)("li",{parentName:"ul"},"Trout"),Object(i.b)("li",{parentName:"ul"},"Tuna"),Object(i.b)("li",{parentName:"ul"},"Turbot"),Object(i.b)("li",{parentName:"ul"},"Flathead "),Object(i.b)("li",{parentName:"ul"},"Tarwhin")),Object(i.b)("h3",{id:"models"},"Models"),Object(i.b)("p",null,"In this project we made use of Convolutional Neural Networks(CNNs) and transfer learning.\nA common way to approach this problem would be download large models trained previously on huge datasets, and fine-tune the model on our custom dataset for the best results."),Object(i.b)("p",null,"Several models were tried and benchmarked such as:"),Object(i.b)("ul",null,Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",Object(a.a)({parentName:"li"},{href:"https://arxiv.org/abs/1608.06993"}),"DenseNet")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",Object(a.a)({parentName:"li"},{href:"https://arxiv.org/abs/1602.07360"}),"AlexnNet")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",Object(a.a)({parentName:"li"},{href:"https://neurohive.io/en/popular-networks/vgg16/"}),"VGG")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",Object(a.a)({parentName:"li"},{href:"https://arxiv.org/abs/1512.03385"}),"Resnet")),Object(i.b)("li",{parentName:"ul"},Object(i.b)("a",Object(a.a)({parentName:"li"},{href:"https://arxiv.org/pdf/1409.4842.pdf"}),"Inception"))),Object(i.b)("p",null,"However the model that best performed and was chosen was DenseNet with an accuracy of ",Object(i.b)("strong",{parentName:"p"},"75%"),". "),Object(i.b)("h3",{id:"training-code"},"Training code"),Object(i.b)("p",null,"For loading and training our model we made use of ",Object(i.b)("a",Object(a.a)({parentName:"p"},{href:"https://pytorch.org/"}),"PyTorch")," and ",Object(i.b)("a",Object(a.a)({parentName:"p"},{href:"https://pytorch.org/docs/stable/torchvision/index.html"}),"TorchVision")," libraries.\nThey house a variety of previously tested and used architectures which can be loaded with or without pre-trained weights and can be used on custom datasets for research/deployment."),Object(i.b)("h3",{id:"deployment-code"},"Deployment Code"),Object(i.b)("p",null,"We made use of the ",Object(i.b)("a",Object(a.a)({parentName:"p"},{href:"https://flask.palletsprojects.com/en/1.1.x/"}),"Flask")," library to deploy or model and host it on a server. An easy and intuitive drag and drop front-end was designed for the user."),Object(i.b)("h3",{id:"dateset-and-analysis"},"Dateset and analysis"),Object(i.b)("p",null,"For each fish species, the data was randomly shuffled and a train and validation split was performed.\nThe dataset consists of very noisy and unclear pictures along with very well captured images.\nThe used dataset and was verified by experts in the aquatic domain ad therefore there are some pictures in the training set which belong to the wrong species of the fish."))}d.isMDXComponent=!0},99:function(e,t,n){"use strict";n.d(t,"a",(function(){return p})),n.d(t,"b",(function(){return h}));var a=n(0),r=n.n(a);function i(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function c(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){i(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var l=r.a.createContext({}),d=function(e){var t=r.a.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):c(c({},t),e)),n},p=function(e){var t=d(e.components);return r.a.createElement(l.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return r.a.createElement(r.a.Fragment,{},t)}},b=r.a.forwardRef((function(e,t){var n=e.components,a=e.mdxType,i=e.originalType,o=e.parentName,l=s(e,["components","mdxType","originalType","parentName"]),p=d(n),b=a,h=p["".concat(o,".").concat(b)]||p[b]||u[b]||i;return n?r.a.createElement(h,c(c({ref:t},l),{},{components:n})):r.a.createElement(h,c({ref:t},l))}));function h(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var i=n.length,o=new Array(i);o[0]=b;var c={};for(var s in t)hasOwnProperty.call(t,s)&&(c[s]=t[s]);c.originalType=e,c.mdxType="string"==typeof e?e:a,o[1]=c;for(var l=2;l<i;l++)o[l]=n[l];return r.a.createElement.apply(null,o)}return r.a.createElement.apply(null,n)}b.displayName="MDXCreateElement"}}]);